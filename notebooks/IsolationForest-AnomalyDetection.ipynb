{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1760977487349,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "K9x-yYcsYjy8"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Setup\n",
    "# https://pyod.readthedocs.io/en/latest/\n",
    "# pyod for libraries in anomaly detection\n",
    "#\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Choose which dataset to use\n",
    "DATASET_MODE = \"kddcup99\"\n",
    "# options: \"RT-IOT2022\", \"TON-IoT-Fridge\"\n",
    "# \"cic-ids2018-fri02\", \"cic-ids2018-fri02-sub\", \"cic-ids2018-fri23\",\n",
    "# \"cic-ids2018-thu01\", \"cic-ids2018-thu15\", \"cic-ids2018-thu22\",\n",
    "# \"cic-ids2018-wed14\", \"cic-ids2018-wed21\", \"cic-ids2018-wed28\"\n",
    "DATASET_DIR = \"./datasets\"\n",
    "\n",
    "\n",
    "# Enable lightweight mode to avoid OOM\n",
    "LIGHT_MODE = False          # set False for full data\n",
    "CHUNK_SIZE = 20000         # adjust for Colab (50kâ€“100k recommended)\n",
    "SAMPLE_LIMIT = 200000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6501,
     "status": "ok",
     "timestamp": 1760977493864,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "qQkmbpSHrHuB",
    "outputId": "895e18d6-0137-4692-e65e-f878ea654601"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip3 install -U pyod\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay, classification_report,\n",
    "    roc_curve, roc_auc_score\n",
    ")\n",
    "from sklearn import tree\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.utils.data import evaluate_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30497,
     "status": "ok",
     "timestamp": 1760977524374,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "sJjUB1Z2_iRf",
    "outputId": "7bab4916-17c5-4ff1-a07c-5e4388b4fcd9"
   },
   "outputs": [],
   "source": [
    "\n",
    "if DATASET_MODE == \"RT-IOT2022\":\n",
    "    !pip3 install -U ucimlrepo\n",
    "    from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "    dataset = fetch_ucirepo(id=942)\n",
    "    X = dataset.data.features\n",
    "    y = dataset.data.targets\n",
    "    benign_labels = ['Thing_Speak', 'MQTT_Publish', 'NMAP_XMAS_TREE_SCAN', 'NMAP_TCP_scan',\n",
    "                 'NMAP_OS_DETECTION', 'NMAP_UDP_SCAN', 'Wipro_bulb', 'NMAP_FIN_SCAN',\n",
    "                 'DOS_SYN_Hping']\n",
    "    malicious_column = \"Attack_type\"\n",
    "    EXCLUDE_FROM_SCALING = []\n",
    "    #benign_labels = ['Thing_Speak', 'MQTT_Publish', 'Wipro_bulb',\n",
    "    #                 'NMAP_FIN_SCAN', 'NMAP_OS_DETECTION', 'NMAP_TCP_scan',\n",
    "    #                 'NMAP_UDP_SCAN', 'NMAP_XMAS_TREE_SCAN']\n",
    "\n",
    "\n",
    "elif DATASET_MODE.startswith(\"cic-ids2018-\"):\n",
    "    benign_labels = ['Benign']\n",
    "    malicious_column = \"Label\"\n",
    "    EXCLUDE_FROM_SCALING = ['time_sin', 'time_cos']\n",
    "    if DATASET_MODE == \"cic-ids2018-fri02\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-fri02-sub\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Friday-02-03-2018_TrafficForML_CICFlowMeter.subset.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-fri23\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-thu01\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-thu15\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-thu22\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-wed14\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-wed21\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    elif DATASET_MODE == \"cic-ids2018-wed28\":\n",
    "      filename = \"/content/drive/MyDrive/datasets-anomaly-detection/CIC-IDS2018/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "\n",
    "\n",
    "    df =  pd.read_csv(filename, low_memory=True)\n",
    "    # Attempt to parse timestamp automatically\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    # Extract hour, minute, and second\n",
    "    df[\"hour\"] = df[\"Timestamp\"].dt.hour.fillna(0)\n",
    "    df[\"minute\"] = df[\"Timestamp\"].dt.minute.fillna(0)\n",
    "    df[\"second\"] = df[\"Timestamp\"].dt.second.fillna(0)\n",
    "\n",
    "    # Compute cyclical time features\n",
    "    df[\"time_sin\"] = np.sin(2 * np.pi * ((df[\"hour\"] + (df[\"minute\"] + df[\"second\"] / 60) / 60) / 24))\n",
    "    df[\"time_cos\"] = np.cos(2 * np.pi * ((df[\"hour\"] + (df[\"minute\"] + df[\"second\"] / 60) / 60) / 24))\n",
    "\n",
    "    # Drop timestamp and raw time components (keep only sin/cos)\n",
    "    df = df.drop(columns=[\"Timestamp\", \"hour\", \"minute\", \"second\"])\n",
    "\n",
    "    X = df.drop(columns=[malicious_column])\n",
    "    y = df[[malicious_column]] if malicious_column in df.columns else None\n",
    "    print(f\"Loaded chunk shape: {df.shape}\")\n",
    "\n",
    "elif DATASET_MODE == \"TON-IoT-Fridge\":\n",
    "  benign_labels = False\n",
    "  malicious_column = \"label\"\n",
    "  EXCLUDE_FROM_SCALING = ['time_sin', 'time_cos']\n",
    "\n",
    "  filename = \"/content/drive/MyDrive/datasets-anomaly-detection/TON-IoT/Train_Test_IoT_Fridge.csv\"\n",
    "  df = pd.read_csv(filename, low_memory=True)\n",
    "  df[\"Timestamp\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "\n",
    "  # Extract hour, minute, and second\n",
    "  df[\"hour\"] = df[\"Timestamp\"].dt.hour.fillna(0)\n",
    "  df[\"minute\"] = df[\"Timestamp\"].dt.minute.fillna(0)\n",
    "  df[\"second\"] = df[\"Timestamp\"].dt.second.fillna(0)\n",
    "\n",
    "  # Compute cyclical time features\n",
    "  df[\"time_sin\"] = np.sin(2 * np.pi * ((df[\"hour\"] + (df[\"minute\"] + df[\"second\"] / 60) / 60) / 24))\n",
    "  df[\"time_cos\"] = np.cos(2 * np.pi * ((df[\"hour\"] + (df[\"minute\"] + df[\"second\"] / 60) / 60) / 24))\n",
    "\n",
    "  # Drop timestamp and raw time components (keep only sin/cos)\n",
    "  df = df.drop(columns=[\"Timestamp\", \"hour\", \"minute\", \"second\", \"time\", 'date', 'type'])\n",
    "\n",
    "  df['temp_condition'] = df['temp_condition'].astype(str).str.strip()\n",
    "\n",
    "  X = df.drop(columns=[malicious_column])\n",
    "  y = df[[malicious_column]] if malicious_column in df.columns else None\n",
    "  print(f\"Loaded chunk shape: {df.shape}\")\n",
    "\n",
    "elif DATASET_MODE == \"kddcup99\":\n",
    "  benign_labels = [b\"normal.\"]\n",
    "  malicious_column = \"labels\"\n",
    "  EXCLUDE_FROM_SCALING = []\n",
    "  from sklearn.datasets import fetch_kddcup99\n",
    "  df = fetch_kddcup99(subset=\"SA\", percent10=True, as_frame=True).frame\n",
    "  X = df.drop(columns=[malicious_column])\n",
    "  y = df[[malicious_column]] if malicious_column in df.columns else None\n",
    "  print(f\"Loaded chunk shape: {df.shape}\")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Initial column names: {X.columns.values}\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7324,
     "status": "ok",
     "timestamp": 1760977531733,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "81zXSfI9rycQ",
    "outputId": "282a8ec7-7972-4e06-eae5-3c46e07950cc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# drop NaN or invalid\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "\n",
    "\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns\n",
    "# Identify time features to exclude from scaling\n",
    "\n",
    "# Automatically exclude only those that exist\n",
    "excluded_features = [col for col in EXCLUDE_FROM_SCALING if col in num_cols]\n",
    "num_cols_to_scale = [col for col in num_cols if col not in excluded_features]\n",
    "\n",
    "if len(X) < 5e5:\n",
    "    log_transformer = FunctionTransformer(lambda arr: np.log1p(np.abs(arr)))\n",
    "else:\n",
    "    log_transformer = FunctionTransformer(lambda arr: arr)  # passthrough for big data\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('log', log_transformer),\n",
    "    ('scaler', RobustScaler(quantile_range=(5, 95)))\n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, num_cols_to_scale),\n",
    "    (\"passthrough\", \"passthrough\", excluded_features),\n",
    "    (\"cat\", categorical_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# Fit on a sample to reduce memory if data huge\n",
    "sample_rows = min(SAMPLE_LIMIT, len(X))\n",
    "preprocessor.fit(X.sample(sample_rows, random_state=42))\n",
    "\n",
    "if LIGHT_MODE:\n",
    "  # Transform in smaller batches\n",
    "  def transform_in_chunks(preprocessor, X, chunk_size=CHUNK_SIZE):\n",
    "      chunks = []\n",
    "      for i in range(0, len(X), chunk_size):\n",
    "          X_chunk = X.iloc[i:i+chunk_size]\n",
    "          X_trans = preprocessor.transform(X_chunk)\n",
    "          chunks.append(X_trans)\n",
    "      return np.vstack([c.toarray() if hasattr(c, \"toarray\") else c for c in chunks])\n",
    "  print(\"Transform\")\n",
    "  # Apply transformation safely\n",
    "  X_scaled = transform_in_chunks(preprocessor, X)\n",
    "else:\n",
    "# Apply transformations\n",
    "  X_scaled = preprocessor.transform(X)\n",
    "\n",
    "# print(np.min(X_scaled), np.max(X_scaled))\n",
    "# print(np.mean(X_scaled), np.std(X_scaled))\n",
    "\n",
    "\n",
    "# Get proper column names\n",
    "num_features = np.array(num_cols)\n",
    "cat_features = np.array([])\n",
    "if len(cat_cols) > 0:\n",
    "    cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
    "feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "\n",
    "# Construct final DataFrame\n",
    "X = pd.DataFrame(X_scaled, columns=feature_names, index=X.index)\n",
    "\n",
    "print(f\"Numeric cols: {len(num_cols)}, Categorical cols: {len(cat_cols)}\")\n",
    "print(f\"Final feature count: {X.shape[1]}\")\n",
    "print(X.head())\n",
    "\n",
    "print(cat_cols)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3206,
     "status": "ok",
     "timestamp": 1760977534931,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "VURRGUE-tiG3",
    "outputId": "8c4e956a-5a14-44ec-898c-ebe05127c156"
   },
   "outputs": [],
   "source": [
    "if benign_labels:\n",
    "    y_binary = y[malicious_column].apply(lambda v: 0 if v.strip() in benign_labels else 1)\n",
    "    print(f\"Benign: {(y_binary == 0).sum()} | Anomaly: {(y_binary == 1).sum()}\")\n",
    "else:\n",
    "    y_binary = y[malicious_column]\n",
    "# print the labels for benign and non-benign attacks\n",
    "print(benign_labels)\n",
    "# print the labels that are not benign, ie.e malicious\n",
    "print(y_binary.unique())\n",
    "\n",
    "contamination_ratio = (y_binary == 1).sum() / ((y_binary == 1).sum() + (y_binary == 0).sum())\n",
    "print(f\"Anomaly ratio for full data: {contamination_ratio}\")\n",
    "\n",
    "# Split benign data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.40, random_state=4\n",
    ")\n",
    "\n",
    "# Combine benign test data and malicious data for the overall test set\n",
    "# X_test = pd.concat([X_test_benign, X.loc[y_malicious.index]])\n",
    "# y_test = pd.concat([y_test_benign, y_malicious])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1760977535011,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "bcfef147",
    "outputId": "73aefd22-c67a-4072-847f-a54b1d5beefd"
   },
   "outputs": [],
   "source": [
    "# Get the original labels that are not in the benign_labels list\n",
    "malicious_labels = y[y_binary == 1][malicious_column].unique()\n",
    "\n",
    "print(\"Malicious attack types:\")\n",
    "print(malicious_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113514,
     "status": "ok",
     "timestamp": 1760977648545,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "jOtJdWxqk77n",
    "outputId": "4fc20327-e03a-44ae-f6de-37bf34f5be33"
   },
   "outputs": [],
   "source": [
    "clf_name = 'IForest'\n",
    "\n",
    "max_samples = 0.02\n",
    "# ensure min number of samples is at least 1\n",
    "if isinstance(max_samples, float):\n",
    "    max_samples = max(256, int(max_samples * X_train.shape[0]))\n",
    "\n",
    "clf = IForest(random_state=5, n_estimators=500, contamination=min(0.5, max(0.02, contamination_ratio)),\n",
    "              max_samples=max_samples, behaviour='new')\n",
    "print(clf.get_params())\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 60564,
     "status": "ok",
     "timestamp": 1760977709133,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "qnHvbfYAX9LW",
    "outputId": "6cbd9810-2e3f-453c-e50a-0cd6eb0cd219"
   },
   "outputs": [],
   "source": [
    "y_train_pred = clf.labels_\n",
    "y_train_scores = clf.decision_scores_\n",
    "\n",
    "y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "\n",
    "# evaluate and print the results\n",
    "print(\"\\nEvaluation On Training Data:\")\n",
    "evaluate_print(clf_name, y_train, y_train_scores)\n",
    "\n",
    "print(\"\\nEvaluation On Test Data:\")\n",
    "evaluate_print(clf_name, y_test, y_test_scores)\n",
    "\n",
    "# example of the feature importance\n",
    "feature_importance = clf.feature_importances_\n",
    "print(feature_names)\n",
    "for i, v in enumerate(feature_importance):\n",
    "    print(f'Feature: {feature_names[i]}, Score: {v:.5f}')\n",
    "print(\"Feature importance\", feature_importance)\n",
    "\n",
    "\n",
    "# Sort and display top 10 features by importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nTop 10 features by importance:\")\n",
    "for i, row in importance_df.head(10).iterrows():\n",
    "    print(f\"{i+1:2d}. {row['Feature']:30s} {row['Importance']:.6f}\")\n",
    "# Features with no importance\n",
    "print(\"\\nFeatures with no importance:\")\n",
    "for i, row in importance_df[importance_df['Importance'] == 0].iterrows():\n",
    "    print(f\"{i+1:2d}. {row['Feature']:30s} {row['Importance']:.6f}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Display as text\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Pretty plot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benign (0)\", \"Anomaly (1)\"])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Isolation Forest Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report for precision, recall, F1\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Benign\", \"Anomaly\"]))\n",
    "\n",
    "sklearn_iforest = clf.detector_  # The underlying sklearn IsolationForest\n",
    "trees = sklearn_iforest.estimators_\n",
    "print(f\"Number of trees: {len(trees)}\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "tree.plot_tree(\n",
    "    trees[0],  # visualize the first tree\n",
    "    filled=True,\n",
    "    feature_names=X.columns,\n",
    "    max_depth=3  # limit depth for readability\n",
    ")\n",
    "plt.title(\"Isolation Forest - Tree 0\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 98,
     "status": "ok",
     "timestamp": 1760977709244,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "BnuGfHDyTCzU",
    "outputId": "bff7f4f1-714e-4f71-c97e-e3695ebca65c"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Combine both in one bar chart\n",
    "plt.bar(importance_df.head(10)[\"Feature\"], importance_df.head(10)[\"Importance\"], color=\"tab:blue\", label=\"Top 10\")\n",
    "plt.bar(importance_df.tail(10)[\"Feature\"], importance_df.tail(10)[\"Importance\"], color=\"tab:red\", label=\"Bottom 10\")\n",
    "\n",
    "plt.title(\"Top and Bottom 10 Feature Importances (Isolation Forest)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7443,
     "status": "ok",
     "timestamp": 1760977716690,
     "user": {
      "displayName": "Filip Andersson",
      "userId": "15415000852055350976"
     },
     "user_tz": -120
    },
    "id": "v7dSw7gDbiQJ",
    "outputId": "6e19601d-be76-4e55-bada-1e944c6d90aa"
   },
   "outputs": [],
   "source": [
    "# Lower scores = more anomalous\n",
    "X_test_anomalies = X_test.copy()\n",
    "X_test_anomalies[\"score\"] = y_test_scores\n",
    "X_test_anomalies[\"label\"] = y_test_pred\n",
    "\n",
    "# Sort anomalies by score (lowest first)\n",
    "top_anomalies = X_test_anomalies.sort_values(by=\"score\", ascending=True).head(5)\n",
    "print(\"Top 5 most anomalous samples:\")\n",
    "display(top_anomalies)\n",
    "\n",
    "# Compute median of normal samples for reference\n",
    "normal_median = X_test[y_test_pred == 1].median()\n",
    "\n",
    "# Pick one example anomaly\n",
    "anomaly_idx = top_anomalies.index[0]\n",
    "anomaly = X_test.loc[anomaly_idx]\n",
    "\n",
    "# Compute deviation from normal behavior\n",
    "deviation = (anomaly - normal_median).abs().sort_values(ascending=False)\n",
    "print(\"Top 10 feature deviations for this anomaly:\")\n",
    "print(deviation.head(10))\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "top_features = deviation.head(3).index  # 3 most deviating features\n",
    "\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.histplot(X_test[feature], bins=50, kde=True, color=\"blue\", label=\"Normal\")\n",
    "    plt.axvline(anomaly[feature], color=\"red\", linestyle=\"--\", label=\"Anomaly\")\n",
    "    plt.title(f\"{feature} â€” distribution vs anomaly value\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNlZBaLpa+dorRIoiRq5aVs",
   "mount_file_id": "1f82aIqdzj60N8MXGRroMt4ItD54pcYWg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
